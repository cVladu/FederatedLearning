{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "6I9SiUI01reb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646249995011,
     "user_tz": -120,
     "elapsed": 3346,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "# import tensorflow_federated as tff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import tqdm\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pathlib"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UUAALZ_T1red",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646249995012,
     "user_tz": -120,
     "elapsed": 20,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 200\n",
    "\n",
    "MAX_SEQ_LENGTH = 20  # might not use\n",
    "NUM_FEATUIRES = 2048"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "HDSWWWow1ref",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646249995013,
     "user_tz": -120,
     "elapsed": 18,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_video(path, max_frames=None, resize=None):\n",
    "    npy_path = pathlib.Path(path).with_suffix('.npy')\n",
    "    if os.path.isfile(npy_path):\n",
    "      if resize is None:\n",
    "        print(\"Falling back to resize=(IMG_SIZE, IMG_SIZE)\")\n",
    "        resize = (IMG_SIZE, IMG_SIZE)\n",
    "      frames = np.load(npy_path, allow_pickle=True)\n",
    "      return np.array([cv2.resize(frame, resize) for frame in frames])\n",
    "\n",
    "    cap =  cv2.VideoCapture(path)\n",
    "    try:\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if max_frames and len(frames) >= max_frames:\n",
    "                break\n",
    "            if resize is not None:\n",
    "              frame = cv2.resize(frame, resize)\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "GrGmoEH_1reg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646249995013,
     "user_tz": -120,
     "elapsed": 16,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def video_frame_generator(path, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "\n",
    "    cap =  cv2.VideoCapture(path)\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            yield frame\n",
    "    finally:\n",
    "        cap.release()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zGRprLW91rei",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646249995014,
     "user_tz": -120,
     "elapsed": 16,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def build_feature_extractor(model='InceptionV3'):\n",
    "    extractor_dict = \\\n",
    "        {\n",
    "            'InceptionV3': keras.applications.inception_v3.InceptionV3,\n",
    "            'VGG16': keras.applications.vgg16.VGG16,\n",
    "            'VGG19': keras.applications.vgg19.VGG19,\n",
    "            'ResNet50': keras.applications.resnet.ResNet50,\n",
    "            'Xception': keras.applications.xception.Xception,\n",
    "            'InceptionResNetV2': keras.applications.inception_resnet_v2.InceptionResNetV2,\n",
    "            'MobileNet': keras.applications.mobilenet.MobileNet,\n",
    "            'MobileNetV2': keras.applications.mobilenet_v2.MobileNetV2,\n",
    "            'DenseNet121': keras.applications.densenet.DenseNet121,\n",
    "            'DenseNet169': keras.applications.densenet.DenseNet169,\n",
    "            'DenseNet201': keras.applications.densenet.DenseNet201,\n",
    "            'EfficientNetB0': keras.applications.efficientnet.EfficientNetB0,\n",
    "            'EfficientNetB1': keras.applications.efficientnet.EfficientNetB1,\n",
    "            'EfficientNetB2': keras.applications.efficientnet.EfficientNetB2,\n",
    "            'EfficientNetB3': keras.applications.efficientnet.EfficientNetB3,\n",
    "            'EfficientNetB4': keras.applications.efficientnet.EfficientNetB4,\n",
    "            'EfficientNetB5': keras.applications.efficientnet.EfficientNetB5,\n",
    "            'EfficientNetB6': keras.applications.efficientnet.EfficientNetB6,\n",
    "            'EfficientNetB7': keras.applications.efficientnet.EfficientNetB7,\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        feature_extractor = extractor_dict[model](include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='avg')\n",
    "    except KeyError:\n",
    "        print(\"Model not found\")\n",
    "        print(\"Falling back to InceptionV3\")\n",
    "        feature_extractor = extractor_dict['InceptionV3'](include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='avg')\n",
    "    preprocess_dict = \\\n",
    "        {\n",
    "            'InceptionV3': keras.applications.inception_v3.preprocess_input,\n",
    "            'VGG16': keras.applications.vgg16.preprocess_input,\n",
    "            'VGG19': keras.applications.vgg19.preprocess_input,\n",
    "            'ResNet50': keras.applications.resnet.preprocess_input,\n",
    "            'Xception': keras.applications.xception.preprocess_input,\n",
    "            'InceptionResNetV2': keras.applications.inception_resnet_v2.preprocess_input,\n",
    "            'MobileNet': keras.applications.mobilenet.preprocess_input,\n",
    "            'MobileNetV2': keras.applications.mobilenet_v2.preprocess_input,\n",
    "            'DenseNet121': keras.applications.densenet.preprocess_input,\n",
    "            'DenseNet169': keras.applications.densenet.preprocess_input,\n",
    "            'DenseNet201': keras.applications.densenet.preprocess_input,\n",
    "            'NASNetLarge': keras.applications.nasnet.preprocess_input,\n",
    "            'NASNetMobile': keras.applications.nasnet.preprocess_input,\n",
    "            'EfficientNetB0': keras.applications.efficientnet.preprocess_input,\n",
    "            'EfficientNetB1': keras.applications.efficientnet.preprocess_input,\n",
    "            'EfficientNetB2': keras.applications.efficientnet.preprocess_input,\n",
    "            'EfficientNetB3': keras.applications.efficientnet.preprocess_input,\n",
    "            'EfficientNetB4': keras.applications.efficientnet.preprocess_input,\n",
    "            'EfficientNetB5': keras.applications.efficientnet.preprocess_input,\n",
    "            'EfficientNetB6': keras.applications.efficientnet.preprocess_input,\n",
    "            'EfficientNetB7': keras.applications.efficientnet.preprocess_input,\n",
    "        }\n",
    "    try:\n",
    "        preprocess = preprocess_dict[model]\n",
    "    except KeyError:\n",
    "        print(\"Model not found\")\n",
    "        print(\"Falling back to InceptionV3\")\n",
    "        preprocess = preprocess_dict['InceptionV3']\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess(inputs)\n",
    "    features = feature_extractor(preprocessed)\n",
    "\n",
    "    return tf.keras.Model(inputs, features)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "fxXCyfu41rej",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646249995014,
     "user_tz": -120,
     "elapsed": 14,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def build_autoencoder(feature_extractor: tf.keras.Model = None, units=None, units_mask=None, initial_n_frames: int = MAX_SEQ_LENGTH) -> tf.keras.Model:\n",
    "    if units is None or units == []:\n",
    "       units = [128]\n",
    "\n",
    "    # Inputs\n",
    "    inputs = tf.keras.layers.Input(shape=(initial_n_frames, feature_extractor.output_shape[1]))\n",
    "\n",
    "    if len(units) == 1:\n",
    "        # Only one encoder and decoder\n",
    "        encoder = tf.keras.layers.LSTM(units=units[0], return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "\n",
    "        decoder_lstm = tf.keras.layers.LSTM(units=units[0], return_state=True, return_sequences=False)\n",
    "        decoder_outputs, _, _ = decoder_lstm(inputs, initial_state=[state_h, state_c])\n",
    "    else:\n",
    "        internal_states = []\n",
    "        # Encoder\n",
    "\n",
    "        # First encoder\n",
    "        encoder = tf.keras.layers.LSTM(units=units[0], return_state=True, return_sequences=True, name='encoder_0')\n",
    "        encoder_outputs, state_h, state_c = encoder(inputs)\n",
    "        internal_states.append([state_h, state_c])\n",
    "\n",
    "        # Residual encoder and decoder\n",
    "        for i, unit in enumerate(units[1:-1]):\n",
    "           encoder = tf.keras.layers.LSTM(units=unit, return_state=True, return_sequences=True, name=f'encoder_{i+1}')\n",
    "           encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
    "           internal_states.append([state_h, state_c])\n",
    "\n",
    "        # Last encoder\n",
    "        encoder = tf.keras.layers.LSTM(units=units[-1], return_state=True, return_sequences=False, name=f'encoder_{len(units)-1}')\n",
    "        encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
    "        internal_states.append([state_h, state_c])\n",
    "\n",
    "        # Decoder\n",
    "\n",
    "        # First decoder\n",
    "        decoder = tf.keras.layers.LSTM(units=units[-1], return_state=True, return_sequences=True, name='decoder_0')\n",
    "        if units_mask[0]:\n",
    "            decoder_outputs, _, _ = decoder(inputs, initial_state=internal_states[-1])\n",
    "        else:\n",
    "            decoder_outputs, _, _ = decoder(inputs)\n",
    "\n",
    "        for i, (unit, internal_state, mask) in enumerate(zip(units[0:-1:-1], internal_states[0:-1:-1], units_mask)):\n",
    "            decoder = tf.keras.layers.LSTM(units=unit, return_sequences=True, name=f'decoder_{i+1}')\n",
    "            if mask:\n",
    "                decoder_outputs = decoder(decoder_outputs, initial_state=internal_state)\n",
    "            else:\n",
    "                decoder_outputs = decoder(decoder_outputs)\n",
    "\n",
    "        # Last decoder\n",
    "        decoder = tf.keras.layers.LSTM(units=units[0], return_state=True, return_sequences=False, name=f'decoder_{len(units)-1}')\n",
    "        if units_mask[-1]:\n",
    "            decoder_outputs, _, _ = decoder(decoder_outputs, initial_state=internal_states[0])\n",
    "        else:\n",
    "            decoder_outputs, _, _ = decoder(decoder_outputs)\n",
    "\n",
    "    decoder_dense = Dense(units=feature_extractor.output_shape[1], activation='relu')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=decoder_outputs)\n",
    "    return model"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-Rukz_q11rel",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646249995015,
     "user_tz": -120,
     "elapsed": 14,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class ULSTMModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, feature_extractor: str,\n",
    "                 autoencoder_units,\n",
    "                 initial_n_frames: int = MAX_SEQ_LENGTH,\n",
    "                 units_mask=None,\n",
    "                 finetune_feature_extractor: bool = False,\n",
    "                 **kwargs):\n",
    "        super(ULSTMModel, self).__init__(**kwargs)\n",
    "        self.feature_extractor = build_feature_extractor(feature_extractor)\n",
    "        self.feature_extractor.trainable = False\n",
    "        self.autoencoder = build_autoencoder(feature_extractor=self.feature_extractor, units=autoencoder_units, units_mask=units_mask, initial_n_frames=initial_n_frames)\n",
    "\n",
    "    def __call__(self, inputs, training=True):\n",
    "        outputs = self.autoencoder(inputs, training=training)\n",
    "        return outputs\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Yr71OSPA1rem",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646264859554,
     "user_tz": -120,
     "elapsed": 404,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "colab_used = False\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  colab_used = True\n",
    "except ImportError:\n",
    "  pass\n",
    "\n",
    "if colab_used:\n",
    "  drive.mount('/gdrive', force_remount=True)\n",
    "  UCF_Crime_NormalVideos_path = '/gdrive/MyDrive/Colab Notebooks/Ongoing Work/dataset/Training-Normal-Videos-Part-1'\n",
    "else:\n",
    "  UCF_Crime_NormalVideos_path = '../../dataset/UCF-Crime/Training-Normal-Videos-Part-1'\n",
    "\n",
    "UCF_Crime_TrainingNormalVideos = os.listdir(UCF_Crime_NormalVideos_path)\n",
    "UCF_Crime_TrainingNormalVideos = [os.path.join(UCF_Crime_NormalVideos_path, video) for video in UCF_Crime_TrainingNormalVideos]\n",
    "random.shuffle(UCF_Crime_TrainingNormalVideos)\n",
    "\n",
    "# 20% of the videos will be used for validation\n",
    "UCF_Crime_ValidationNormalVideos = UCF_Crime_TrainingNormalVideos[:int(len(UCF_Crime_TrainingNormalVideos) * 0.2)]\n",
    "\n",
    "# 80% of the dataset for training\n",
    "UCF_Crime_TrainingNormalVideos = UCF_Crime_TrainingNormalVideos[int(len(UCF_Crime_TrainingNormalVideos) * 0.2):]\n",
    "\n",
    "npz_dataset_path = '/gdrive/MyDrive/Colab Notebooks/Ongoing Work/dataset/' if colab_used else '../../dataset/'"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Hy3xlhF1ren",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646250020778,
     "user_tz": -120,
     "elapsed": 25774,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    },
    "outputId": "2d56e249-85bc-4f6f-f29f-0a3bcf4142c2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"for video in tqdm.tqdm(UCF_Crime_ValidationNormalVideos + UCF_Crime_TrainingNormalVideos):\n",
    "  path = pathlib.Path(video)\n",
    "  try:\n",
    "    np.save(path.with_suffix('.npy'), load_video(video, max_frames=3000)) \n",
    "  except OSError:\n",
    "    if colab_used:\n",
    "      drive.mount('/gdrive', force_remount=True)\"\"\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "0_QX-7tqDP33",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646250020779,
     "user_tz": -120,
     "elapsed": 10,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    },
    "outputId": "37e0f643-97a4-488e-84dd-5832330acc4b"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"for video in tqdm.tqdm(UCF_Crime_ValidationNormalVideos + UCF_Crime_TrainingNormalVideos):\\n  path = pathlib.Path(video)\\n  try:\\n    np.save(path.with_suffix('.npy'), load_video(video, max_frames=3000)) \\n  except OSError:\\n    if colab_used:\\n      drive.mount('/gdrive', force_remount=True)\""
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/gdrive/MyDrive/Colab Notebooks/Ongoing Work/dataset/X_EfficientNetB0_(256, 256)32_training.npy exists: False\n",
      "/gdrive/MyDrive/Colab Notebooks/Ongoing Work/dataset/y_EfficientNetB0_(256, 256)32_training.npy exists: False\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 688/688 [2:54:23<00:00, 15.21s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/gdrive/MyDrive/Colab Notebooks/Ongoing Work/dataset/X_EfficientNetB0_(256, 256)32_validation.npy exists: False\n",
      "/gdrive/MyDrive/Colab Notebooks/Ongoing Work/dataset/y_EfficientNetB0_(256, 256)32_validation.npy exists: False\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 171/171 [40:26<00:00, 14.19s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, videos, batch_size, n_frames, shuffle=True, resize=(IMG_SIZE, IMG_SIZE), feature_extractor=None, samples_per_video=2, partition='training'):\n",
    "        self.samples_per_video = samples_per_video\n",
    "        self.batch_size = batch_size\n",
    "        self.n_frames = n_frames\n",
    "        self.shuffle = shuffle\n",
    "        self.resize = resize\n",
    "        if feature_extractor is None:\n",
    "          raise NotImplementedError(\"Pass a feature extractor\")\n",
    "        else:\n",
    "          self.feature_extractor = build_feature_extractor(feature_extractor)\n",
    "        self.partition = partition\n",
    "        self.__initVideoData(videos, feature_extractor)\n",
    "        self.data_length = len(videos) * self.samples_per_video\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __initVideoData(self, videos, feature_extractor):\n",
    "      X_path = os.path.join(npz_dataset_path, f'X_{feature_extractor}_{self.resize}{self.n_frames}_{self.partition}.npy')\n",
    "      y_path = os.path.join(npz_dataset_path, f'y_{feature_extractor}_{self.resize}{self.n_frames}_{self.partition}.npy')\n",
    "      print(f'{X_path} exists: {os.path.isfile(X_path)}')\n",
    "      print(f'{y_path} exists: {os.path.isfile(y_path)}')\n",
    "      if os.path.isfile(X_path) and os.path.isfile(y_path):\n",
    "        self.X = np.load(X_path)\n",
    "        self.y = np.load(y_path)\n",
    "      else:\n",
    "        self.X = np.empty((len(videos) * self.samples_per_video, self.n_frames, self.feature_extractor.output_shape[-1]))\n",
    "        self.y = np.empty((len(videos) * self.samples_per_video, self.feature_extractor.output_shape[-1]))\n",
    "        for v, video in enumerate(tqdm.tqdm(videos)):\n",
    "          frames = load_video(video, resize=self.resize, max_frames=self.samples_per_video*self.n_frames)\n",
    "          if len(frames) <= self.n_frames:\n",
    "            continue\n",
    "          # Take sample from the current video\n",
    "          for s in range(self.samples_per_video):\n",
    "            start_frame = np.random.randint(0, len(frames) - self.n_frames - 1)\n",
    "            end_frame = start_frame + self.n_frames\n",
    "            for j, frame in enumerate(frames[start_frame:end_frame]):\n",
    "              self.X[v * self.samples_per_video + s, j, :] = self.feature_extractor(frame[np.newaxis])\n",
    "            self.y[v * self.samples_per_video + s, :] = self.feature_extractor(frames[end_frame][np.newaxis])\n",
    "        np.save(os.path.join(npz_dataset_path, f'X_{feature_extractor}_{self.resize}{self.n_frames}_{self.partition}'), self.X)\n",
    "        np.save(os.path.join(npz_dataset_path, f'y_{feature_extractor}_{self.resize}{self.n_frames}_{self.partition}'), self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data_length / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index * self.batch_size: (index + 1) * self.batch_size, :, :]\n",
    "        y = self.y[index * self.batch_size: (index + 1) * self.batch_size, :]\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.data_length)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "feature_extractor='EfficientNetB0'\n",
    "initial_n_frames=32\n",
    "train_data_generator_params = {'videos': UCF_Crime_TrainingNormalVideos, 'batch_size': 32, 'n_frames': initial_n_frames, 'shuffle': True, 'feature_extractor': feature_extractor}\n",
    "validation_data_generator_params = {'videos': UCF_Crime_ValidationNormalVideos, 'batch_size': 32, 'n_frames': initial_n_frames, 'shuffle': False, 'feature_extractor': feature_extractor, 'partition': 'validation'}\n",
    "\n",
    "training_generator = DataGenerator(**train_data_generator_params)\n",
    "validation_generator = DataGenerator(**validation_data_generator_params)\n",
    "\n",
    "print(len(training_generator))\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "DbDRn6dn1reo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "190c420c-6a7b-46c0-99e0-24e887746c06",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646263070779,
     "user_tz": -120,
     "elapsed": 12899684,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    lr_list = [1e-2] * 40 + [1e-3] * 50 + [1e-4] * 100 + [1e-5] * 10\n",
    "\n",
    "    return lr_list[epoch]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NJnTTPQ61rep",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646264815000,
     "user_tz": -120,
     "elapsed": 461,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "models_path = '/gdrive/MyDrive/Colab Notebooks/Ongoing Work/models' if colab_used else '../../models/UCF-Crime'\n",
    "autoencoder_units=[128, 64, 32]\n",
    "units_mask=[True, True, True]\n",
    "model_instance = ULSTMModel(feature_extractor=feature_extractor,\n",
    "                             autoencoder_units=autoencoder_units,\n",
    "                             initial_n_frames=initial_n_frames,\n",
    "                             units_mask=units_mask,\n",
    "                             finetune_feature_extractor=False, \n",
    "                             name=f'ULSTM_{feature_extractor}_{initial_n_frames}')\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=f'{models_path}/{feature_extractor}/ULSTM{initial_n_frames}_{\"-\".join(str(x) for x in zip(autoencoder_units, units_mask))}',\n",
    "                                    monitor='val_loss',\n",
    "                                    save_best_only=True, save_weights_only=True, save_format='tf'),\n",
    "    keras.callbacks.TensorBoard(log_dir=f\"{models_path}/logs/{feature_extractor}/ULSTM{initial_n_frames}\", write_graph=True, write_images=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='auto'),\n",
    "    keras.callbacks.TerminateOnNaN(),\n",
    "    keras.callbacks.LearningRateScheduler(lr_scheduler),\n",
    "    keras.callbacks.BackupAndRestore(backup_dir=f'{models_path}/BackupAndRestore/{feature_extractor}/ULSTM{initial_n_frames}_{\"-\".join(str(x) for x in zip(autoencoder_units, units_mask))}'),\n",
    "]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Z-E3QL6k1req",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646266524433,
     "user_tz": -120,
     "elapsed": 5350,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0866 - mean_absolute_error: 0.2007 - cosine_similarity: 0.5765 - logcosh: 0.0394 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0729 - mean_absolute_error: 0.1870 - cosine_similarity: 0.6640 - logcosh: 0.0337 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0663 - mean_absolute_error: 0.1794 - cosine_similarity: 0.7002 - logcosh: 0.0308 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0624 - mean_absolute_error: 0.1752 - cosine_similarity: 0.7204 - logcosh: 0.0292 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 6s 134ms/step - loss: 0.0584 - mean_absolute_error: 0.1707 - cosine_similarity: 0.7398 - logcosh: 0.0274 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0557 - mean_absolute_error: 0.1676 - cosine_similarity: 0.7552 - logcosh: 0.0262 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0533 - mean_absolute_error: 0.1651 - cosine_similarity: 0.7649 - logcosh: 0.0252 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0494 - mean_absolute_error: 0.1600 - cosine_similarity: 0.7826 - logcosh: 0.0235 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0467 - mean_absolute_error: 0.1565 - cosine_similarity: 0.7951 - logcosh: 0.0223 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0450 - mean_absolute_error: 0.1541 - cosine_similarity: 0.8025 - logcosh: 0.0215 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0435 - mean_absolute_error: 0.1520 - cosine_similarity: 0.8097 - logcosh: 0.0208 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0413 - mean_absolute_error: 0.1488 - cosine_similarity: 0.8191 - logcosh: 0.0198 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0398 - mean_absolute_error: 0.1465 - cosine_similarity: 0.8259 - logcosh: 0.0191 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0385 - mean_absolute_error: 0.1444 - cosine_similarity: 0.8314 - logcosh: 0.0185 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0393 - mean_absolute_error: 0.1458 - cosine_similarity: 0.8280 - logcosh: 0.0189 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0376 - mean_absolute_error: 0.1431 - cosine_similarity: 0.8350 - logcosh: 0.0181 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0359 - mean_absolute_error: 0.1401 - cosine_similarity: 0.8426 - logcosh: 0.0173 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0346 - mean_absolute_error: 0.1379 - cosine_similarity: 0.8481 - logcosh: 0.0167 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0335 - mean_absolute_error: 0.1359 - cosine_similarity: 0.8529 - logcosh: 0.0162 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0327 - mean_absolute_error: 0.1344 - cosine_similarity: 0.8565 - logcosh: 0.0158 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0321 - mean_absolute_error: 0.1335 - cosine_similarity: 0.8587 - logcosh: 0.0156 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0319 - mean_absolute_error: 0.1330 - cosine_similarity: 0.8600 - logcosh: 0.0154 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0317 - mean_absolute_error: 0.1328 - cosine_similarity: 0.8605 - logcosh: 0.0154 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0310 - mean_absolute_error: 0.1314 - cosine_similarity: 0.8636 - logcosh: 0.0150 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0303 - mean_absolute_error: 0.1302 - cosine_similarity: 0.8663 - logcosh: 0.0147 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0302 - mean_absolute_error: 0.1300 - cosine_similarity: 0.8671 - logcosh: 0.0146 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 6s 127ms/step - loss: 0.0296 - mean_absolute_error: 0.1289 - cosine_similarity: 0.8699 - logcosh: 0.0144 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0290 - mean_absolute_error: 0.1278 - cosine_similarity: 0.8721 - logcosh: 0.0141 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0296 - mean_absolute_error: 0.1288 - cosine_similarity: 0.8698 - logcosh: 0.0144 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0297 - mean_absolute_error: 0.1293 - cosine_similarity: 0.8697 - logcosh: 0.0144 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0289 - mean_absolute_error: 0.1277 - cosine_similarity: 0.8726 - logcosh: 0.0141 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0292 - mean_absolute_error: 0.1282 - cosine_similarity: 0.8713 - logcosh: 0.0142 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0287 - mean_absolute_error: 0.1273 - cosine_similarity: 0.8734 - logcosh: 0.0139 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0279 - mean_absolute_error: 0.1258 - cosine_similarity: 0.8762 - logcosh: 0.0136 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0278 - mean_absolute_error: 0.1256 - cosine_similarity: 0.8771 - logcosh: 0.0135 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0284 - mean_absolute_error: 0.1266 - cosine_similarity: 0.8743 - logcosh: 0.0138 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0280 - mean_absolute_error: 0.1259 - cosine_similarity: 0.8765 - logcosh: 0.0136 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0273 - mean_absolute_error: 0.1246 - cosine_similarity: 0.8793 - logcosh: 0.0133 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0270 - mean_absolute_error: 0.1241 - cosine_similarity: 0.8801 - logcosh: 0.0132 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0267 - mean_absolute_error: 0.1233 - cosine_similarity: 0.8819 - logcosh: 0.0130 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0100\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0248 - mean_absolute_error: 0.1193 - cosine_similarity: 0.8897 - logcosh: 0.0121 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0239 - mean_absolute_error: 0.1170 - cosine_similarity: 0.8934 - logcosh: 0.0117 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0236 - mean_absolute_error: 0.1161 - cosine_similarity: 0.8948 - logcosh: 0.0115 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0234 - mean_absolute_error: 0.1156 - cosine_similarity: 0.8955 - logcosh: 0.0114 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0233 - mean_absolute_error: 0.1152 - cosine_similarity: 0.8961 - logcosh: 0.0113 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0232 - mean_absolute_error: 0.1150 - cosine_similarity: 0.8965 - logcosh: 0.0113 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0231 - mean_absolute_error: 0.1147 - cosine_similarity: 0.8968 - logcosh: 0.0113 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0230 - mean_absolute_error: 0.1146 - cosine_similarity: 0.8971 - logcosh: 0.0112 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0229 - mean_absolute_error: 0.1144 - cosine_similarity: 0.8974 - logcosh: 0.0112 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 50/200\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0229 - mean_absolute_error: 0.1143 - cosine_similarity: 0.8977 - logcosh: 0.0112 - val_loss: nan - val_mean_absolute_error: nan - val_cosine_similarity: nan - val_logcosh: nan - lr: 0.0010\n",
      "Epoch 50: early stopping\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fbe92b990>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model_instance.compile(optimizer='adam', loss='mse', \n",
    "                       metrics=[tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.CosineSimilarity(), tf.keras.metrics.LogCoshError()],\n",
    "                       run_eagerly=True)\n",
    "model_instance.fit(x=training_generator,\n",
    "                   validation_data=validation_generator,\n",
    "                   epochs=EPOCHS,\n",
    "                   callbacks=callbacks)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "EzUwTp3M1req",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1646266806438,
     "user_tz": -120,
     "elapsed": 282025,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "512bd551-308e-4296-d772-df3c910208fa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/Xception/ULSTM16"
   ],
   "metadata": {
    "id": "yaV6nI13B_Tl",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1646250163248,
     "user_tz": -120,
     "elapsed": 16,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "YEAuOopXGcNc",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1646250163248,
     "user_tz": -120,
     "elapsed": 15,
     "user": {
      "displayName": "Catalin Vladu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10198749064472537368"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "ULSTM_experimenting_notebook.ipynb",
   "provenance": [
    {
     "file_id": "1vCgTnGbnjvFjbvz4XW6Ym8jrWR3-ZD6G",
     "timestamp": 1645819019362
    }
   ]
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}